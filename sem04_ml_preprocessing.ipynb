{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар №4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Дьячкова Екатерина Николаевна\n",
    "\n",
    "вуз: МГУ \n",
    "\n",
    "факультет: механико-математический\n",
    "\n",
    "курс: 6\n",
    "\n",
    "кафедра: теории вероятностей\n",
    "\n",
    "научный руководитель: Яровая Е.Б."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Семинар подготовлен с целью ознакомить слушателей с процедурой подготовки данных для алгоритмов машнинного обучения на примере задачи оценки цены недвижимости. Описание данных можно найти в data_description.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Считывание данных (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считайте данные из файлов train.csv и test.csv в массивы:\n",
    "trainX (содержит признаки обучающего множества)\n",
    "trainY (содержит правильные ответа для обучающего множества)\n",
    "testX (содержит признаки для тестового множества)\n",
    "\n",
    "Первый столбец содержит порядковый номер объекта, поэтому его рекомендуется сразу удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79) (1460,) (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trainX = pd.read_csv('train.csv')\n",
    "testX = pd.read_csv('test.csv').drop('Id', axis = 1)\n",
    "trainY = trainX.SalePrice\n",
    "trainX = trainX.drop(['Id', 'SalePrice'], axis = 1)\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60 'RL' 65.0 8450 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
      " 'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
      " 'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
      " 'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2 1\n",
      " 3 1 'Gd' 8 'Typ' 0 nan 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61 0 0\n",
      " 0 0 nan nan nan 0 2 2008 'WD' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "print(trainX.iloc[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Предварительная обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило \"реальные\" данные содержат пропущенные значения и прочие нечисловые признаки, поэтому прежде чем запустить методы fit и  predict модели, необходимо сделать все признаки числовыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Обработка пропущенных значений (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучите раздел документации https://scikit-learn.org/stable/modules/impute.html#impute и параметры классов SimpleImputer и MissingIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6965\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "indicator = MissingIndicator()\n",
    "train_mask_missing_values_only = indicator.fit_transform(trainX)\n",
    "test_mask_missing_values_only = indicator.fit_transform(testX)\n",
    "print(np.sum(train_mask_missing_values_only))\n",
    "print(np.sum(test_mask_missing_values_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных были обнаружены пропущенные значение. \n",
    "При помощи класса MissingIndicator устраните пропущенные значения, использовав самый часто встречаемый элемент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy = 'most_frequent')  \n",
    "\n",
    "trainX_without_missing = imp.fit_transform(trainX)\n",
    "testX_without_missing = imp.fit_transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "indicator = MissingIndicator()\n",
    "train_mask_missing_values_only = indicator.fit_transform(trainX_without_missing)\n",
    "test_mask_missing_values_only = indicator.fit_transform(testX_without_missing)\n",
    "print(np.sum(train_mask_missing_values_only))\n",
    "print(np.sum(test_mask_missing_values_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущенные значения удалены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60 'RL' 65.0 8450 'Pave' 'Grvl' 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
      " 'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
      " 'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
      " 'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2 1\n",
      " 3 1 'Gd' 8 'Typ' 0 'Gd' 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61 0\n",
      " 0 0 0 'Gd' 'MnPrv' 'Shed' 0 2 2008 'WD' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "print(trainX_without_missing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Обработка категориальных значений (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучите раздел документации https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features\n",
    "\n",
    "При помощи класса OrdinalEncoder удалите категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "train_part = np.concatenate([trainX_without_missing, np.ones((len(trainX_without_missing), 1))], axis = 1)\n",
    "test_part = np.concatenate([testX_without_missing, np.zeros((len(testX_without_missing), 1))], axis = 1)\n",
    "\n",
    "all_data = np.concatenate([train_part, test_part], axis = 0)\n",
    "all_data_without_missing_and_cat = enc.fit_transform(all_data)\n",
    "\n",
    "trainX_without_missing_and_cat = np.delete(all_data_without_missing_and_cat[all_data_without_missing_and_cat[:, 79] > 0], 79, 1)\n",
    "testX_without_missing_and_cat = np.delete(all_data_without_missing_and_cat[all_data_without_missing_and_cat[:, 79] < 1], 79, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.   3.  41. 619.   1.   0.   3.   3.   0.   4.   0.   5.   2.   2.\n",
      "   0.   5.   6.   4. 110.  53.   1.   1.  12.  13.   1. 148.   2.   4.\n",
      "   2.   2.   3.   3.   2. 512.   5.   0. 107. 261.   1.   0.   1.   4.\n",
      " 197. 356.   0. 766.   1.   0.   2.   1.   3.   1.   2.   6.   6.   0.\n",
      "   2.   1.  94.   1.   2. 283.   4.   4.   2.   0.  52.   0.   0.   0.\n",
      "   0.   2.   2.   2.   0.   1.   2.   8.   4.]\n"
     ]
    }
   ],
   "source": [
    "print(trainX_without_missing_and_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь данные готовы для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите достоинства и недостатки данного метода обработки категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +\n",
    "\n",
    "1) Можем использовать больше методов машинного обучения, не удаляя категориальные переменные (не все работают с нечисловыми признаками).\n",
    "\n",
    "### $-$\n",
    "\n",
    "1) В категориальных признаках возникает отношение порядка (может привести к неверному предсказанию).\n",
    "\n",
    "2) Если применять OrdinalEncoder.fit_transform() ко всем данным (не только к категориальным признакам), числовые признаки тоже поменяют свои значения (станет не 1,2,3, а 0,1,2), что теоретически может привести к неверному предсказанию.\n",
    "\n",
    "3) Необходимо сначала соединять test и train, кодировать, а уже потом разделять, чтобы одинаковые категории в train и test были закодированы одинаковым числом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "F = [['female'], ['female'], ['female']]\n",
    "M = [['male'], ['male'], ['male']]\n",
    "print(enc.fit_transform(F))\n",
    "print(enc.fit_transform(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Разделение данных на обучение и валидацию (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите обучающее множество на обучение(75%) и валидацию(25%), воспользовавшись функцией train_test_split с random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainX_without_missing_and_cat, trainY, random_state=42) #25% -- значение по умолчанию => не указываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 79) (365, 79) (1095,) (365,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Обучение моделей (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные готовы для обучения алгоритмов машинного обучения. В качестве базовой можеди возьмём линейную регрессию, меткрика качества - mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3831817295997663\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текущую модель можно существенно улучшить. Добейтесь на валидации ошибки меньше 0.03 без каких-либо ограничений на алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02917992469036821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "s_scaler = MinMaxScaler()\n",
    "scaled_X = s_scaler.fit_transform(trainX_without_missing_and_cat)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(scaled_X, trainY, random_state=42)\n",
    "\n",
    "param = {'alpha': np.random.uniform(low = 0.0, high = 100, size = 1000)}\n",
    "regr = RandomizedSearchCV(Lasso(), param, n_iter = 20, cv = 5, refit = True)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_val)\n",
    "y_pred[y_pred < 0.0] = np.mean(y_pred[y_pred > 0.0])\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Способы улучшения качества модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Применить другую стратегию обработки пропущенных значений из scikit-learn (1 балл + 1 балл, если получили прирост качества для алгоритма с ошибкой меньше 0.03 )\n",
    "\n",
    "2. Добавить бинарные признаки отсутствия/присутствия значения для столбцов, где есть пропущенные значения (1 балл)\n",
    "\n",
    "3. Реализовать самостоятельно одну из стратегий обработки пропущенных значений из семинара (начиная с kNN) (2 балла)\n",
    "\n",
    "4. Применить стратегию OneHotEncoder  для обработки категориальных признаков (2 балла)\n",
    "\n",
    "5. Применить стратегию агрегированния данных для обработки категориальных признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте не менее двух идей из предложенных выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Добавляем бинарные признаки отсутствия/присутствия значения для столбцов с пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = MissingIndicator()\n",
    "\n",
    "train_int_mask = indicator.fit_transform(trainX).astype(int)\n",
    "new_ftrs_train = trainX.iloc[:, indicator.features_].columns.tolist()\n",
    "new_ftrs_train = [x + '_nan_ind' for x in new_ftrs_train]\n",
    "new_ftrs = pd.DataFrame(train_int_mask, columns = new_ftrs_train)\n",
    "trainX_with_new_ftrs = pd.concat([trainX, new_ftrs], axis = 1)\n",
    "\n",
    "test_int_mask = indicator.fit_transform(testX).astype(int)\n",
    "new_ftrs_test = testX.iloc[:, indicator.features_].columns.tolist()\n",
    "new_ftrs_test = [x + '_nan_ind' for x in new_ftrs_test]\n",
    "new_ftrs = pd.DataFrame(test_int_mask, columns = new_ftrs_test)\n",
    "testX_with_new_ftrs = pd.concat([testX, new_ftrs], axis = 1)\n",
    "\n",
    "imp = SimpleImputer(strategy = 'most_frequent')  \n",
    "\n",
    "trainX_without_missing_with_new_ftrs = pd.DataFrame(imp.fit_transform(trainX_with_new_ftrs), columns = trainX_with_new_ftrs.columns)\n",
    "testX_without_missing_with_new_ftrs = pd.DataFrame(imp.fit_transform(testX_with_new_ftrs), columns = testX_with_new_ftrs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79) (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "print(trainX_without_missing.shape, testX_without_missing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ячейках выше я показала только то, как добавлять нужные признаки (то есть сделала это для train и test по-отдельности). Уже по размеру результата видно, что в train и test пропуски находятся в разных столбцах.\n",
    "В итоговую модель мы должны будем предоставлять данные с одинаковым количеством столбцов (предполагаю, что и их смысл должен быть одинаковым). Теперь поступить можно двумя способами: заполнить нулями дополнительные столбцы в train/test, либо удалить несовпадающие столбцы. Воспользуемся вторым вариантом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_without_missing_with_new_ftrs['train_ind'] = np.ones(len(trainX_without_missing_with_new_ftrs))\n",
    "testX_without_missing_with_new_ftrs['train_ind'] = np.zeros(len(testX_without_missing_with_new_ftrs))\n",
    "\n",
    "and_columns = set(trainX_without_missing_with_new_ftrs.columns) & set(testX_without_missing_with_new_ftrs.columns)\n",
    "\n",
    "all_data = pd.concat([trainX_without_missing_with_new_ftrs.loc[:, and_columns], testX_without_missing_with_new_ftrs.loc[:, and_columns]], axis = 0)\n",
    "\n",
    "# повторяем OriginalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "all_data_without_missing_and_cat_with_new_ftrs = pd.DataFrame(enc.fit_transform(all_data), columns = all_data.columns)\n",
    "\n",
    "trainX_without_missing_and_cat_with_new_ftrs = all_data_without_missing_and_cat_with_new_ftrs[all_data_without_missing_and_cat_with_new_ftrs['train_ind'] > 0].drop('train_ind', axis = 1)\n",
    "testX_without_missing_and_cat_with_new_ftrs = all_data_without_missing_and_cat_with_new_ftrs[all_data_without_missing_and_cat_with_new_ftrs['train_ind'] < 1].drop('train_ind', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02924859323497884\n"
     ]
    }
   ],
   "source": [
    "# проверим на улучшенной модели из пункта 4.\n",
    "\n",
    "scaled_X = s_scaler.fit_transform(trainX_without_missing_and_cat)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(scaled_X, trainY, random_state=42)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_val)\n",
    "y_pred[y_pred < 0.0] = np.mean(y_pred[y_pred > 0.0])\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. One-Hot Encoding (без OneHotEncoder, через pd.get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# через файл с описанием найдем все возможные категориальные признаки, сопоставим их с теми, что есть в train/testX, получим список категориальных признаков в наших данных\n",
    "ctgrcl_ftrs_frm_data_desc = set(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleType', 'SaleCondition'])\n",
    "ctgrcl_ftrs = set(trainX.columns) & ctgrcl_ftrs_frm_data_desc\n",
    "\n",
    "# перед кодированием объединим train и test данные (берем те, что уже без пропусков, из пункта 2.1), чтобы избежать ситуации, когда, например, в test не вошли какие-то категории из train и мы закодируем их по-отдельности некорректно\n",
    "train_data = pd.DataFrame(trainX_without_missing, columns = trainX.columns)\n",
    "train_data['train_ind'] = np.ones(len(train_data))\n",
    "test_data = pd.DataFrame(testX_without_missing, columns = testX.columns)\n",
    "test_data['train_ind'] = np.zeros(len(test_data))\n",
    "all_data = pd.concat([train_data, test_data], axis = 0)\n",
    "\n",
    "# кодируем все категориальные признаки, удаляя по 1 столбцу на каждую категорию, чтобы избежать мультиколлинеарности\n",
    "data_with_dummies = pd.get_dummies(all_data, columns = ctgrcl_ftrs, drop_first = True)\n",
    "\n",
    "# разделяем данные обратно, удаляя последний фиктивный стобец\n",
    "trainX_without_missing_one_hot = data_with_dummies[data_with_dummies['train_ind'] > 0].drop(['train_ind'], axis = 1)\n",
    "testX_without_missing_one_hot = data_with_dummies[data_with_dummies['train_ind'] < 1].drop(['train_ind'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Katy/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 681654213.2753296, tolerance: 503373949.3139316\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/Katy/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861228854.3135376, tolerance: 503373949.3139316\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/Katy/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 504406634.3829346, tolerance: 503373949.3139316\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/Katy/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 905389580.8644409, tolerance: 503373949.3139316\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02377953588481211\n"
     ]
    }
   ],
   "source": [
    "# проверим на улучшенной модели из пункта 4.\n",
    "\n",
    "scaled_X = s_scaler.fit_transform(trainX_without_missing_one_hot)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(scaled_X, trainY, random_state=42)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_val)\n",
    "y_pred[y_pred < 0.0] = np.mean(y_pred[y_pred > 0.0])\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
